import os
from dotenv import load_dotenv
from splitter import split_docs_by_markdown_headers
from loader import load_docs
from langchain_openai import OpenAIEmbeddings
from langchain_pinecone import PineconeVectorStore
from pinecone import Pinecone

embeddings = OpenAIEmbeddings(model="text-embedding-3-large")

def embedding():
    load_dotenv()
    openai_api_key = os.getenv("OPENAI_API_KEY")
    pinecone_api_key = os.getenv("PINECONE_API_KEY")

    pc = Pinecone(api_key=pinecone_api_key)
    index_name = "test"
    index = pc.Index(index_name)


    # 1. åŠ è½½æ–‡æ¡£
    root = "D:/GitHub_Repos/InterviewAndLeetCode/é¢è¯•é¢˜"
    print("æ­£åœ¨åŠ è½½æ–‡æ¡£...")
    docs = load_docs(root)
    print("âœ… æ–‡æ¡£åŠ è½½å®Œæˆï¼Œå…±", len(docs), "ä¸ªæ–‡æ¡£")

    # 2. æŒ‰ Markdown æ ‡é¢˜å±‚çº§åˆ‡åˆ†æ–‡æ¡£
    print("æ­£åœ¨æŒ‰æ ‡é¢˜åˆ‡åˆ†æ–‡æ¡£...")
    chunks = split_docs_by_markdown_headers(docs)
    print(f"âœ… æŒ‰æ ‡é¢˜åˆ‡åˆ†å®Œæˆï¼Œå…± {len(chunks)} ä¸ªå—")
    print("ç¤ºä¾‹ chunkï¼š\n", chunks[7].page_content[:300])

    # 3. åˆ›å»ºå‘é‡embeddingæ¨¡å‹
    print("æ­£åœ¨åˆ›å»º Embedding æ¨¡å‹...")
    embeddings = OpenAIEmbeddings(model="text-embedding-3-large", api_key=openai_api_key)
    print("âœ… Embedding æ¨¡å‹åˆ›å»ºå®Œæˆ")

    # 4. å†™å…¥å‘é‡æ•°æ®åº“
    print("æ­£åœ¨å°†å‘é‡å†™å…¥ Pinecone å‘é‡æ•°æ®åº“...")
    vectorstore = PineconeVectorStore(
        index=index,
        embedding=embeddings,
        text_key="page_content"
    )

    vectorstore.add_documents(chunks, batch_size=64) # åˆ†æ‰¹å†™å…¥ï¼Œé¿å…ä¸€æ¬¡æ€§æ•°æ®é‡è¿‡å¤§å¤ªæ…¢
    print("ğŸ‰ Embedding + Pinecone ingest å®Œæˆï¼")

if __name__ == "__main__":
    embedding()